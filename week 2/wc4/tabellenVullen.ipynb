{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>De connectie leggen tussen SSMS en Python</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect('..\\\\..\\\\sqllite\\\\go_sales.sqlite')\n",
    "conn2 = sqlite3.connect('..\\\\..\\\\sqllite\\\\go_crm.sqlite')\n",
    "conn3 = sqlite3.connect('..\\\\..\\\\sqllite\\\\go_staff.sqlite')\n",
    "\n",
    "# Connect to SQL Server\n",
    "DB = {'servername': 'LAPTOP-HSI9FLRD\\\\SQLEXPRESS',\n",
    "      'database': 'DataWarehouseGreatOutdoors'}\n",
    "\n",
    "export_conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] +\n",
    "                             ';DATABASE=' + DB['database'] + ';Trusted_Connection=yes')\n",
    "\n",
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "# properties\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Products table</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from SQLite database\n",
    "products = pd.read_sql_query(\"SELECT * FROM product\", conn)\n",
    "product_types = pd.read_sql_query(\"SELECT * FROM product_type\", conn)\n",
    "product_line = pd.read_sql_query(\"SELECT * FROM product_line\", conn)\n",
    "\n",
    "# Merge data into one table\n",
    "combined_product_table = pd.merge(products, product_types, on='PRODUCT_TYPE_CODE')\n",
    "combined_product_table = pd.merge(combined_product_table, product_line, on='PRODUCT_LINE_CODE')\n",
    "combined_product_table\n",
    "\n",
    "# Iterate through rows and insert into SQL Server\n",
    "for index, row in combined_product_table.iterrows():\n",
    "    try:\n",
    "        query = \"INSERT INTO Product (PRODUCT_NUMBER, PRODUCT_NAME, PRODUCT_DESCRIPTION, PRODUCT_PRODUCT_LINE_NAME, PRODUCT_PRODUCT_TYPE_NAME, PRODUCT_PRODUCT_COST_AMOUNT, PRODUCT_MARGIN_AMOUNT) VALUES (?, ?, ?, ?, ?, ?, ?)\"\n",
    "        export_cursor.execute(query, row['PRODUCT_NUMBER'], row['PRODUCT_NAME'], row['DESCRIPTION'], row['PRODUCT_LINE_EN'], row['PRODUCT_TYPE_EN'], row['PRODUCTION_COST'], row['MARGIN'])\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error inserting row {index}: {e}\")\n",
    "\n",
    "export_conn.commit() \n",
    "# export_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Satisfaction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from SQLite database\n",
    "satisfaction = pd.read_sql_query(\"SELECT * FROM satisfaction\", conn3)\n",
    "satisfaction_type = pd.read_sql_query(\"SELECT * FROM satisfaction_type\", conn3)\n",
    "\n",
    "# Merge data into one table\n",
    "combined_satisfaction_table = pd.merge(satisfaction, satisfaction_type, on='SATISFACTION_TYPE_CODE')\n",
    "\n",
    "# Iterate through rows and insert into SQL Server\n",
    "for index, row in combined_satisfaction_table.iterrows():\n",
    "    try:\n",
    "        query = \"INSERT INTO Satisfaction (SATISFACTION_TYPE_CODE, SATISFACTION_TYPE_DESCRIPTION, SALES_STAFF_CODE, YEAR) VALUES (?, ?, ?, ?)\"\n",
    "        export_cursor.execute(query, row['SATISFACTION_TYPE_CODE'], row['SATISFACTION_TYPE_DESCRIPTION'], row['SALES_STAFF_CODE'], row['YEAR'])\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error inserting row {index}: {e}\")\n",
    "\n",
    "export_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from SQLite database\n",
    "training = pd.read_sql_query(\"SELECT * FROM training\", conn3)\n",
    "course = pd.read_sql_query(\"SELECT * FROM course\", conn3)\n",
    "\n",
    "# Merge data into one table\n",
    "combined_training_table = pd.merge(training, course, on='COURSE_CODE')\n",
    "\n",
    "# Iterate through rows and insert into SQL Server\n",
    "for index, row in combined_training_table.iterrows():\n",
    "    try:\n",
    "        query = \"INSERT INTO Course (COURSE_CODE, COURSE_DESCRIPTION, SALES_STAFF_CODE, YEAR) VALUES (?, ?, ?, ?)\"\n",
    "        export_cursor.execute(query, row['COURSE_CODE'], row['COURSE_DESCRIPTION'], row['SALES_STAFF_CODE'], row['YEAR'])\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error inserting row {index}: {e}\")\n",
    "\n",
    "export_conn.commit()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Retailer table</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from SQLite database\n",
    "retailer = pd.read_sql_query(\"SELECT * FROM retailer\", conn2)\n",
    "retailer_type = pd.read_sql_query(\"SELECT * FROM retailer_type\", conn2)\n",
    "retailer_headquarters = pd.read_sql_query(\"SELECT * FROM retailer_headquarters\", conn2)\n",
    "retailer_site = pd.read_sql_query(\"SELECT * FROM retailer_site\", conn)\n",
    "country = pd.read_sql_query(\"SELECT * FROM country\", conn2)\n",
    "\n",
    "# Merge data into one table\n",
    "combined_retailer_table = pd.merge(retailer, retailer_type, on='RETAILER_TYPE_CODE')\n",
    "combined_retailer_table = pd.merge(combined_retailer_table, retailer_headquarters, on='RETAILER_CODEMR')\n",
    "combined_retailer_table = pd.merge(combined_retailer_table, retailer_site, on= 'RETAILER_CODE')\n",
    "combined_retailer_table = pd.merge(combined_retailer_table, country, left_on= 'COUNTRY_CODE_x', right_on= 'COUNTRY_CODE')\n",
    "combined_retailer_table\n",
    "# print(combined_retailer_table.columns)\n",
    "\n",
    "# Iterate through rows and insert into SQL Server\n",
    "for index, row in combined_retailer_table.iterrows():\n",
    "    try:\n",
    "        query = \"INSERT INTO Retailer (RETAILER_CODE, RETAILER_CODE_MR, RETAILER_COMPANY_NAME, RETAILER_COUNTRY_NAME, RETAILER_POSTAL_ZONE_NAME, RETAILER_REGION_NAME, RETAILER_CITY_NAME, RETAILER_SALES_TERRITORY_NAME, RETAILER_ADDRESS_1_NAME, RETAILER_ADDRESS_2_NAME, RETAILER_RETAILER_TYPE, RETAILER_RETAILER_HEADQUARTERS, RETAILER_SITE_CODE) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "        export_cursor.execute(query, row['RETAILER_CODE'], row['RETAILER_CODEMR'], row['COMPANY_NAME'], \n",
    "                              row['COUNTRY_EN'], row['POSTAL_ZONE_x'], row['REGION_x'], row['CITY_x'], row['SALES_TERRITORY_CODE'], \n",
    "                              row['ADDRESS1_x'], row['ADDRESS2_x'], row['RETAILER_TYPE_CODE'], row['RETAILER_NAME'], row['RETAILER_SITE_CODE'])\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error inserting row {index}: {e}\") \n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sales_staff table</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from SQLite database\n",
    "sales_staff = pd.read_sql_query(\"SELECT * FROM sales_staff\", conn)\n",
    "sales_branch = pd.read_sql_query(\"SELECT * FROM sales_branch\", conn)\n",
    "country = pd.read_sql_query(\"SELECT * FROM country\", conn)\n",
    "\n",
    "# Merge data into one table\n",
    "combined_sales_staff_table = pd.merge(sales_staff, sales_branch, on='SALES_BRANCH_CODE')\n",
    "combined_sales_staff_table = pd.merge(combined_sales_staff_table, country, on='COUNTRY_CODE')\n",
    "combined_sales_staff_table\n",
    "\n",
    "# Iterate through rows and insert into SQL Server\n",
    "for index, row in combined_sales_staff_table.iterrows():\n",
    "    try:\n",
    "        # Adjust your INSERT query according to the actual column names in your SQL Server table\n",
    "        query = \"INSERT INTO SALES_STAFF ([Sales_staff_country_name], [Sales_staff_postal_zone_name], [Sales_staff_first_name], [Sales_staff_last_name], [Sales_staff_region_name], [Sales_staff_city_name], [Sales_staff_address_1_name], [Sales_staff_address_2_name], [Sales_staff_position_name], [Sales_staff_code]) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "        export_cursor.execute(query, row['COUNTRY'], row['POSTAL_ZONE'], row['FIRST_NAME'], row['LAST_NAME'], row['REGION'], row['CITY'], row['ADDRESS1'], row['ADDRESS2'], row['POSITION_EN'], row['SALES_STAFF_CODE'])\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error inserting row {index}: {e}\")\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Date table</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>order details table</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from SQLite database\n",
    "order_header = pd.read_sql_query(\"SELECT * FROM order_header\", conn)\n",
    "order_details = pd.read_sql_query(\"SELECT * FROM order_details\", conn)\n",
    "order_method = pd.read_sql_query(\"SELECT * FROM order_method\", conn)\n",
    "\n",
    "\n",
    "# Merge data into one table\n",
    "combined_order_table = pd.merge(order_header, order_details, on='ORDER_NUMBER')\n",
    "combined_order_table = pd.merge(combined_order_table, order_method, on='ORDER_METHOD_CODE')\n",
    "combined_order_table\n",
    "\n",
    "# Iterate through rows and insert into SQL Server\n",
    "for index, row in combined_order_table.iterrows():\n",
    "    try:\n",
    "        # Adjust your INSERT query according to the actual column names in your SQL Server table\n",
    "        query = \"INSERT INTO ORDER_DETAILS ([order_detail_code], [order_number], [order_method_code], [order_method_en], [quantity], [order_detail_unit_cost], [order_detail_unit_price], [order_detail_unit_sale], [order_detail_order_date], [order_detail_product_number], [retailer_site_code], [sales_staff_code]) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "        export_cursor.execute(query, row['ORDER_DETAIL_CODE'], row['ORDER_NUMBER'], row['ORDER_METHOD_CODE'], row['ORDER_METHOD_EN'], row['QUANTITY'], row['UNIT_COST'], row['UNIT_PRICE'], row['UNIT_SALE_PRICE'], row['ORDER_DATE'], row['PRODUCT_NUMBER'], row['RETAILER_SITE_CODE'], row['SALES_STAFF_CODE'])\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error inserting row {index}: {e}\")\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonanalyzer-r8O-sSsi-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
